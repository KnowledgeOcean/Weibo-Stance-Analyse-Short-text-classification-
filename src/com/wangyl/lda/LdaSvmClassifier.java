package com.wangyl.lda;

import java.io.IOException;
import java.util.ArrayList;
import java.util.Vector;

import com.wangyl.config.Config;
import com.wangyl.preprocesser.StructuredPreproedData;
import com.wangyl.svmAPI.svm_predict;
import com.wangyl.svmAPI.svm_train;
import com.wangyl.tools.FileOperateAPI;
import com.wangyl.tools.IOapi;

import libsvm.svm;
import libsvm.svm_model;
import libsvm.svm_node;
import libsvm.svm_parameter;
import libsvm.svm_print_interface;
import libsvm.svm_problem;

/**
 * 
 * @author WangYunli
 * @para_description 
 *
 */
public class LdaSvmClassifier {
	public static svm svmapi=new svm();
	public static final String modelSaveSrc=Config.ldasvmModelDir;
	public static void InitSvmProblem(svm_problem prob,String trainData) {
		
	}
	/*
	 *
	 * `svm-train' Usage
=================
Usage: svm-train [options] training_set_file [model_file]
options:
-s svm_type : set type of SVM (default 0)
	0 -- C-SVC		(multi-class classification)
	1 -- nu-SVC		(multi-class classification)
	2 -- one-class SVM	
	3 -- epsilon-SVR	(regression)
	4 -- nu-SVR		(regression)
-t kernel_type : set type of kernel function (default 2)
	0 -- linear: u'*v
	1 -- polynomial: (gamma*u'*v + coef0)^degree
	2 -- radial basis function: exp(-gamma*|u-v|^2)
	3 -- sigmoid: tanh(gamma*u'*v + coef0)
	4 -- precomputed kernel (kernel values in training_set_file)
-d degree : set degree in kernel function (default 3)
-g gamma : set gamma in kernel function (default 1/num_features)
-r coef0 : set coef0 in kernel function (default 0)
-c cost : set the parameter C of C-SVC, epsilon-SVR, and nu-SVR (default 1)
-n nu : set the parameter nu of nu-SVC, one-class SVM, and nu-SVR (default 0.5)
-p epsilon : set the epsilon in loss function of epsilon-SVR (default 0.1)
-m cachesize : set cache memory size in MB (default 100)
-e epsilon : set tolerance of termination criterion (default 0.001)
-h shrinking : whether to use the shrinking heuristics, 0 or 1 (default 1)
-b probability_estimates : whether to train a SVC or SVR model for probability estimates, 0 or 1 (default 0)
-wi weight : set the parameter C of class i to weight*C, for C-SVC (default 1)
-v n: n-fold cross validation mode
-q : quiet mode (no outputs)

`svm-predict' Usage
===================

Usage: svm-predict [options] test_file model_file output_file
options:
-b probability_estimates: whether to predict probability estimates, 0 or 1 (default 0); for one-class SVM only 0 is supported

model_file is the model file generated by svm-train.
test_file is the test data you want to predict.
svm-predict will produce output in the output_file.
	 */
	public static void run(int n,double c) throws Exception {
		LDA_api.GenerateModelsForEachTagert(Config.LDAInputDir,n);
		ArrayList<StructuredPreproedData> testData=ExtractFeatureBaseLda.ExtractLDAFeatures(Config.ldaSvmFeaturesDir_train, Config.ldaSvmFeaturesDir_test, Config.preprocessedTrainDataOutputSrc, Config.preprocessedTestDataOutputSrc, Config.LDAInputDir,n);
		//ArrayList<StructuredPreproedData> testData=RawDataPreprocesser.LoadTestDataFromPreproedFile();
		for(int i=0;i<testData.size();i++) {
			StructuredPreproedData tmpdata=testData.get(i);
			LdaSvmClassifier.classify(Config.ldaSvmFeaturesDir_train+tmpdata.className+"_feature.txt", Config.ldaSvmFeaturesDir_test+tmpdata.className+"_feature.txt", tmpdata.className,c);
		}
		System.out.println("all works have finished");
	}
	public static double classify(String trainData,String testData,String []trainCmdline,String []predictCmdline) throws IOException {
		//String []paramArrayOfString=trainCmdline.split(" ");
		svm_train.TrainModel(trainCmdline);
		//paramArrayOfString=predictCmdline.split(" ");
		return svm_predict.Predict(predictCmdline);
	}
	public static double classify(String trainData,String testData,String target,double c) throws IOException {
		String trainCmdline="-s 0 -t 0 -c "+c;//+trainData+" "+Config.svmModelSrc;
		String []tmp=trainCmdline.split(" ");
		String []trainCmd=new String[tmp.length+2];
		int i=0;
		for(i=0;i<tmp.length;i++) {
			trainCmd[i]=tmp[i];
		}
		trainCmd[i]=trainData;
		trainCmd[i+1]=Config.ldasvmModelDir+"model";
		String []predictCmd=new String[3];//testData+" "+Config.svmModelSrc+".model "+Config.svmPredictResultSrc;
		predictCmd[0]=testData;
		predictCmd[1]=Config.ldasvmModelDir+"model";
		predictCmd[2]=Config.ldasvmPredictResultDir+target+"_result.txt";
		IOapi.makeSureDirExists(Config.ldasvmModelDir);
		IOapi.makeSureDirExists(Config.ldasvmPredictResultDir);
		return classify(trainData, testData, trainCmd, predictCmd);
	}
	public static double[][] LoadFeatures(String featureFileSrc,ArrayList<Integer> stanceId) {
		IOapi tmpIO=new IOapi(1);
		tmpIO.startRead(featureFileSrc, Config.encodingType, 0);
		String line=tmpIO.readOneSentence(0);
		ArrayList<String> strList=new ArrayList<String>();
		
		while(line!=null) {
			strList.add(line);
			line=tmpIO.readOneSentence(0);
		}
		tmpIO.endRead(0);
		double [][]rst=new double [strList.size()][strList.get(0).split(" ").length-1];
		String []strs;
		stanceId.clear();
		for(int i=0;i<strList.size();i++) {
			strs=strList.get(i).split(" ");
			stanceId.add(Integer.parseInt(strs[0]));
			for(int j=1;j<strs.length;j++) {
				rst[i][j-1]=Double.parseDouble((strs[j].split(":"))[1]);
			}
		}
		return rst;
	}
	
}
/*svm_problem svm_prob=new svm_problem();
InitSvmProblem(svm_prob,trainData);//加载训练数据
svm_parameter svm_para=new svm_parameter();//生成训练参数类
svm_para.svm_type=svm_parameter.C_SVC;//C-SVC n(n>=2)分类器，允许用异常值惩罚因子C进行不完全分类。
svm_para.kernel_type=svm_parameter.RBF;//RBF函数：exp(-γ×|u-v|^2) - 径向基，对于大多数情况都是一个较好的选择：d(x,y) = exp(-gamma*|x-y|2)
svm_para.degree=3; //核函数中的degree设置(默认3)
svm_para.coef0=0;//核函数中的coef0设置(默认0)
svm_para.C=1;//
svm_para.cache_size=100;//
svm_para.shrinking=1;
svm_para.probability=1;

svm_model model=svm.svm_train(svm_prob, svm_para);

try {
	svm.svm_save_model(modelSaveSrc, model);
} catch (IOException e) {
	// TODO 自动生成的 catch 块
	e.printStackTrace();
}

//svm.svm_predict(svm_prob, );
/*svm_print_interface your_print_func = new svm_print_interface()
{ 
	public void print(String s)
	{
		// your own format
	}
};
svm.svm_set_print_string_function(your_print_func);*/

/*
 * public static void main(String[] args) {
	    svm_problem sp = new svm_problem();
	    svm_node[][] x = new svm_node[4][2];
	    for (int i = 0; i < 4; i++) {
	        for (int j = 0; j < 2; j++) {
	            x[i][j] = new svm_node();
	        }
	    }
	    x[0][0].index = 1;
	    x[0][0].value = 0;
	    x[0][1].index = 2;
	    x[0][1].value = 0;

	    x[1][0].index = 1;
	    x[1][0].value = 1;
	    x[1][1].index = 2;
	    x[1][1].value = 1;

	    x[2][0].index = 1;
	    x[2][0].value = 0;
	    x[2][1].index = 2;
	    x[2][1].value = 1;

	    x[3][0].index = 1;
	    x[3][0].value = 1;
	    x[3][1].value = 0;
	    x[3][1].index = 2;


	    double[] labels = new double[]{-1,-1,1,1};
	    sp.x = x;
	    sp.y = labels;
	    sp.l = 4;
	    svm_parameter prm = new svm_parameter();
	    prm.svm_type = svm_parameter.C_SVC;
	    prm.kernel_type = svm_parameter.RBF;
	    prm.C = 1000;
	    prm.eps = 0.0000001;
	    prm.gamma = 10;
	    prm.probability = 1;
	    prm.cache_size=1024;
	    /*
	     * svm_check_parameter
	     * 参数可行返回null，否则返回错误信息
	     *
	    System.out.println("Param Check " + (svm.svm_check_parameter(sp, prm)==null));
	    svm_model model = svm.svm_train(sp, prm);           //训练分类
	    try {
			svm.svm_save_model("svm_model_file", model);
		} catch (IOException e) {
			e.printStackTrace();
		}
	    
	    try {
			svm.svm_load_model("svm_model_file");
		} catch (IOException e) {
			e.printStackTrace();
		}
	    svm_node[] test = new svm_node[]{new svm_node(), new svm_node()};
	    test[0].index = 1;
	    test[0].value = 0;
	    test[1].index = 2;
	    test[1].value = 0;
	    double[] l = new double[2]; 
	    double result_prob = svm.svm_predict_probability(model, test,l);		//测试1，带预测概率的分类测试
	    double result_normal = svm.svm_predict(model, test);    //测试2 不带概率的分类测试
	    System.out.println("Result with prob " + result_prob);
	    System.out.println("Result normal " + result_normal);
	    System.out.println("Probability " + l[0] + "\t" + l[1]);
	}
 */
